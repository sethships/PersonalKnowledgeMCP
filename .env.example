# Personal Knowledge MCP - Environment Configuration Template (Phase 1)
# Copy this file to .env and fill in your actual values

# ============================================================================
# Required: OpenAI API Key for Embedding Generation
# ============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# ============================================================================
# Optional: GitHub Personal Access Token (for private repositories)
# ============================================================================
# Create a PAT at: https://github.com/settings/tokens
# Required scopes: repo (for private repos)
GITHUB_PAT=ghp_your-token-here

# ============================================================================
# ChromaDB Connection (defaults work with docker-compose)
# ============================================================================
CHROMADB_HOST=localhost
CHROMADB_PORT=8000

# ============================================================================
# Data Paths
# ============================================================================
# Directory where repositories will be cloned
REPO_CLONE_PATH=./data/repos

# Base data directory for all persistent data
DATA_PATH=./data

# ============================================================================
# Logging Configuration
# ============================================================================
# Log level: trace, debug, info, warn, error, fatal
LOG_LEVEL=info

# Log format: json or pretty (use pretty for development)
LOG_FORMAT=pretty

# ============================================================================
# Embedding Configuration
# ============================================================================
# OpenAI embedding model (Phase 1 supports text-embedding-3-small only)
EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimensions (1536 for text-embedding-3-small)
EMBEDDING_DIMENSIONS=1536

# ============================================================================
# Chunking Configuration
# ============================================================================
# Maximum tokens per chunk (affects embedding quality vs. granularity)
CHUNK_MAX_TOKENS=500

# Token overlap between consecutive chunks (for context continuity)
CHUNK_OVERLAP_TOKENS=50

# ============================================================================
# File Scanning Configuration
# ============================================================================
# Supported file extensions for indexing (comma-separated, no spaces)
SUPPORTED_EXTENSIONS=.js,.ts,.jsx,.tsx,.cs,.py,.java,.go,.rs,.cpp,.c,.h,.md,.txt,.rst,.json,.yaml,.yml,.toml

# Maximum file size to process (in bytes, 1MB = 1048576)
MAX_FILE_SIZE_BYTES=1048576

# ============================================================================
# Search Configuration
# ============================================================================
# Default number of search results
DEFAULT_SEARCH_LIMIT=10

# Maximum allowed search results
MAX_SEARCH_LIMIT=50

# Default similarity threshold (0.0 to 1.0)
DEFAULT_SIMILARITY_THRESHOLD=0.7

# Maximum length of content snippets in search results (characters)
SNIPPET_MAX_LENGTH=500

# ============================================================================
# Performance Configuration
# ============================================================================
# Maximum batch size for OpenAI embedding API calls (OpenAI limit is 100)
EMBEDDING_BATCH_SIZE=100

# Maximum retries for transient API failures
MAX_RETRIES=3

# Request timeout in milliseconds
REQUEST_TIMEOUT_MS=30000

# ============================================================================
# Development/Debug Settings
# ============================================================================
# Enable debug mode (more verbose logging)
DEBUG=false

# Node environment (development, production, test)
NODE_ENV=development
